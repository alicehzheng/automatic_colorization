{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                   ab_max: 110.0                         \n",
      "                  ab_norm: 110.0                         \n",
      "                 ab_quant: 10.0                          \n",
      "             aspect_ratio: 1.0                           \n",
      "           avg_loss_alpha: 0.986                         \n",
      "               batch_size: 8                             \n",
      "                    beta1: 0.9                           \n",
      "          checkpoints_dir: ./colorization_pytorch/checkpoints\n",
      "           classification: False                         \n",
      "             dataset_mode: aligned                       \n",
      "             display_freq: 200                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 5                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 384                           \n",
      "              epoch_count: 0                             \n",
      "                 fineSize: 384                           \n",
      "                  gpu_ids: 0                             \n",
      "                     half: False                         \n",
      "                 how_many: 200                           \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                   l_cent: 50.0                          \n",
      "                   l_norm: 100.0                         \n",
      "                 lambda_A: 1.0                           \n",
      "                 lambda_B: 1.0                           \n",
      "               lambda_GAN: 0.0                           \n",
      "          lambda_identity: 0.5                           \n",
      "                 loadSize: 384                           \n",
      "               load_model: True                          \n",
      "                       lr: 0.0001                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: lambda                        \n",
      "                mask_cent: 0.5                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \n",
      "                 nThreads: 4                             \n",
      "               n_layers_D: 3                             \n",
      "                     name: experiment_name               \n",
      "                      ndf: 64                            \n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                 no_lsgan: False                         \n",
      "                     norm: batch                         \n",
      "                output_nc: 2                             \n",
      "                    phase: val                           \n",
      "                pool_size: 50                            \n",
      "               print_freq: 200                           \n",
      "           resize_or_crop: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "                sample_Ps: [1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
      "                 sample_p: 1.0                           \n",
      "          save_epoch_freq: 1                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 10000                         \n",
      "                  verbose: False                         \n",
      "          which_direction: AtoB                          \n",
      "              which_epoch: latest                        \n",
      "         which_model_netD: basic                         \n",
      "         which_model_netG: siggraph                      \n",
      "----------------- End -------------------\n",
      "1\n",
      "1\n",
      "siggraph\n",
      "initialize network with normal\n",
      "<bound method Module.type of SIGGRAPHGenerator(\n",
      "  (model1): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model6): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model7): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model8up): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (model8): Sequential(\n",
      "    (0): ReLU(inplace)\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model9up): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (model9): Sequential(\n",
      "    (0): ReLU(inplace)\n",
      "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model10up): Sequential(\n",
      "    (0): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (model10): Sequential(\n",
      "    (0): ReLU(inplace)\n",
      "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (model3short8): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (model2short9): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (model1short10): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (model_class): Sequential(\n",
      "    (0): Conv2d(256, 529, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (model_out): Sequential(\n",
      "    (0): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (upsample4): Sequential(\n",
      "    (0): Upsample(scale_factor=4, mode=nearest)\n",
      "  )\n",
      "  (softmax): Sequential(\n",
      "    (0): Softmax()\n",
      "  )\n",
      ")>\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./colorization_pytorch/checkpoints/experiment_name/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 34.187 M\n",
      "-----------------------------------------------\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 34.187 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "sys.path.append(\"colorization_pytorch\")\n",
    "sys.path.append(\"flownet2_pytorch\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from colorization_pytorch.models import create_model\n",
    "from flownet2_pytorch.models import FlowNet2\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datasets import *\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from colorization_pytorch.options.train_options import TrainOptions\n",
    "from flownet2_pytorch.parser import initialize_args\n",
    "import torchvision.transforms as transforms\n",
    "from colorization_pytorch.util import util\n",
    "\n",
    "class Mask(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Mask,self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=64, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.cnn(data)\n",
    "\n",
    "\n",
    "class VideoColorization(nn.Module):\n",
    "    def __init__(self, opt, args, batchNorm=False, div_flow=20.):\n",
    "        super(VideoColorization,self).__init__()\n",
    "        self.opt = opt\n",
    "        self.color_model = create_model(opt)\n",
    "        self.color_model.setup(opt)\n",
    "        self.color_model.print_networks(False)\n",
    "        self.flownet = FlowNet2(args, batchNorm=batchNorm, div_flow=div_flow)\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        self.flownet.load_state_dict(checkpoint['state_dict'])\n",
    "        #self.ori_index = torch.tensor(list(itertools.product(np.arange(H), np.arange(W)))). \\\n",
    "            #reshape(H, W, -1)\n",
    "        self.mask = Mask(256)\n",
    "\n",
    "    def forward(self, color_data, flow_data):\n",
    "        self.color_model.set_input(color_data[0])\n",
    "        _,_, previous_feature_map = self.color_model.encode()\n",
    "        self.color_model.set_input(color_data[1])\n",
    "        conv1_2, conv2_2, feature_map = self.color_model.encode()\n",
    "        flow = self.flownet(flow_data)  # B * 2 * 384 * 1024\n",
    "        #print(\"flow\")\n",
    "        FlowWeight = F.interpolate(flow, previous_feature_map.size()[-2:], mode='bilinear')\n",
    "        B, C, H, W = previous_feature_map.size()\n",
    "        #print(previous_feature_map.shape)\n",
    "        flow_copy = FlowWeight.clone().detach().cpu().long().permute(0, 2, 3, 1)\n",
    "        predicted_feature_map = torch.zeros(previous_feature_map.shape).cuda()\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                res_h = h + flow_copy[0,h,w,0]\n",
    "                res_w = w + flow_copy[0,h,w,1]\n",
    "                if res_h < 0:\n",
    "                    res_h = 0\n",
    "                elif res_h > H-1:\n",
    "                    res_h = H-1\n",
    "                if res_w < 0:\n",
    "                    res_w = 0\n",
    "                elif res_w > W-1:\n",
    "                    res_w = W-1\n",
    "                predicted_feature_map[:,:,res_h,res_w] = previous_feature_map[:,:,h,w]\n",
    "            \n",
    "        # B*512*22*22\n",
    "        #print(predicted_feature_map.shape)\n",
    "        delta_feature_map = torch.abs(predicted_feature_map - feature_map)\n",
    "        M = self.mask(delta_feature_map)\n",
    "        #print(M.shape)\n",
    "        output_feature_map = (1 - M) * feature_map + M * predicted_feature_map\n",
    "        fake_B_class, fake_B_reg = self.color_model.decode(conv1_2, conv2_2, output_feature_map)\n",
    "        #print(fake_B_reg.shape)\n",
    "        return fake_B_reg, FlowWeight\n",
    "        \n",
    "\n",
    "        \n",
    "class flow_args():\n",
    "    def __init__(self):\n",
    "        self.rgb_max = 255\n",
    "        self.fp16 = False\n",
    "        self.fp16_scale = 1024.\n",
    "        self.crop_size = [384,1024]\n",
    "        self.inference_size = [-1,-1]\n",
    "        self.resume = './check_point/FlowNet2_checkpoint.pth.tar'\n",
    "        \n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "args = flow_args()\n",
    "debug = VideoColorization(opt, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MpiSintel(args, root = \"data/training/\")\n",
    "train_loader = DataLoader(train_set, batch_size = 1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class solver():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.lr = 1e-4\n",
    "        self.optimizer_flow = torch.optim.Adam(self.model.flownet.parameters(), lr=2e-4, weight_decay=1e-6)\n",
    "        self.optimizer_color_network = []\n",
    "        self.use_D = opt.lambda_GAN > 0\n",
    "        self.optimizer_G = torch.optim.Adam(self.model.color_model.netG.parameters(),\n",
    "                                            lr=0, betas=(opt.beta1, 0.999)) #lr=opt.lr\n",
    "        self.optimizer_color_network.append(self.optimizer_G)\n",
    "\n",
    "        if self.use_D:\n",
    "            self.optimizer_D = torch.optim.Adam(self.model.color_model.netD.parameters(),\n",
    "                                                    lr=0, betas=(opt.beta1, 0.999))\n",
    "            self.optimizer_color_network.append(self.optimizer_D)\n",
    "        \n",
    "        self.optimizer_mask = torch.optim.Adam(self.model.mask.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "        self.batch_size = 5\n",
    "        self.epoch = 100\n",
    "        self.H = 384\n",
    "        self.W = 1024\n",
    "        #self.ori_index = torch.tensor(list(itertools.product(np.arange(self.H), np.arange(self.W)))). \\\n",
    "         #   reshape(self.H, self.W, -1)\n",
    "        \n",
    "    def plot_grad_flow(self, named_parameters):\n",
    "        '''Plots the gradients flowing through different layers in the net during training.\n",
    "        Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "        Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "        \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "        ave_grads = []\n",
    "        max_grads= []\n",
    "        layers = []\n",
    "        for n, p in named_parameters:\n",
    "            if(p.requires_grad) and (\"bias\" not in n):\n",
    "                layers.append(n)\n",
    "                ave_grads.append(p.grad.abs().mean())\n",
    "                max_grads.append(p.grad.abs().max())\n",
    "        plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "        plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "        plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "        plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "        plt.xlim(left=0, right=len(ave_grads))\n",
    "        plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "        plt.xlabel(\"Layers\")\n",
    "        plt.ylabel(\"average gradient\")\n",
    "        plt.title(\"Gradient flow\")\n",
    "        plt.grid(True)\n",
    "        plt.legend([matplotlib.lines.Line2D([0], [0], color=\"c\", lw=4),\n",
    "                matplotlib.lines.Line2D([0], [0], color=\"b\", lw=4),\n",
    "                matplotlib.lines.Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "        plt.show()\n",
    "        \n",
    "    def pixel_flow(self, flow, img):\n",
    "        flow_copy = flow.clone().detach().cpu().long().permute(0, 2, 3, 1)\n",
    "        B, C, H, W = img.size()\n",
    "        next_img = torch.zeros(img.shape).cuda()\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                res_h = h + flow_copy[0,h,w,0]\n",
    "                res_w = w + flow_copy[0,h,w,1]\n",
    "                if res_h < 0:\n",
    "                    res_h = 0\n",
    "                elif res_h > H-1:\n",
    "                    res_h = H-1\n",
    "                if res_w < 0:\n",
    "                    res_w = 0\n",
    "                elif res_w > W-1:\n",
    "                    res_w = W-1\n",
    "                next_img[:,:,res_h,res_w] = img[:,:,h,w]\n",
    "        return next_img\n",
    "        \n",
    "    def eval_metric(self, O_1, O_2, flow, mask):\n",
    "        R_2 = self.pixel_flow(flow, O_1)\n",
    "        Estab = torch.sum(mask * (O_2 - R_2) * (O_2 - R_2))\n",
    "        return Estab\n",
    "    \n",
    "    def cohe_loss(self, O_2, S_1, flow, mask):\n",
    "        R_2 = self.pixel_flow(flow, S_1)\n",
    "        L_cohe = torch.sum(mask * (O_2 - R_2) * (O_2 - R_2))\n",
    "        return L_cohe\n",
    "    \n",
    "    def occ_loss(self, O_2, S_2, mask):\n",
    "        L_occ = torch.sum((1-mask) * (O_2 - S_2) * (O_2 - S_2))\n",
    "        return L_occ\n",
    "        \n",
    "    def flow_loss(self, F_est, flow):\n",
    "        F_down = F.interpolate(flow, F_est.size()[-2:], mode='bilinear')\n",
    "        L_flow = torch.sum((F_est-F_down) * (F_est-F_down))\n",
    "        return L_flow\n",
    "        \n",
    "    def train(self, train_loader):\n",
    "        alpha = 1e-5\n",
    "        beta = 2e-4\n",
    "        gamma = 20\n",
    "        for epoch in range(1, self.epoch):\n",
    "            batch = 0\n",
    "            for Img, flow, mask in train_loader:\n",
    "                Img = Img.cuda()\n",
    "                flow = flow.cuda()\n",
    "                mask = mask.type(torch.FloatTensor).cuda()\n",
    "                #print(flow.shape)\n",
    "                #print(mask.shape)\n",
    "                temp_1 = util.get_colorization_data(Img[:,:,0,:,:].unsqueeze(0),self.model.opt)\n",
    "                I_1 = temp_1['A'].unsqueeze(1)\n",
    "                S_1 = temp_1['B']\n",
    "                I_1 = I_1.repeat(1,3,1,1,1)\n",
    "                temp_2 = util.get_colorization_data(Img[:,:,1,:,:].unsqueeze(0),self.model.opt)\n",
    "                I_2 = temp_2['A'].unsqueeze(1)\n",
    "                S_2 = temp_2['B']\n",
    "                I_2 = I_2.repeat(1,3,1,1,1)\n",
    "                inp = torch.cat((I_1,I_2), dim=2)\n",
    "                self.optimizer_flow.zero_grad()\n",
    "                self.optimizer_G.zero_grad()\n",
    "                self.optimizer_mask.zero_grad()\n",
    "                O_2, F_est = self.model([temp_1,temp_2],inp)\n",
    "                #print(F_est.shape)\n",
    "                loss = alpha*self.cohe_loss(O_2,S_1,flow,mask)+beta*self.occ_loss(O_2,S_2,mask)+gamma*self.flow_loss(F_est,flow)\n",
    "                print(batch,loss)\n",
    "                loss.backward()\n",
    "                self.optimizer_flow.step()\n",
    "                #self.optimizer_G.step()\n",
    "                self.optimizer_mask.step()\n",
    "                del Img\n",
    "                del flow\n",
    "                del mask\n",
    "                batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(633217.2500, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "debug = debug.cuda()\n",
    "solv = solver(debug)\n",
    "solv.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(1,3,4).squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(96,256,2).cuda()\n",
    "b = torch.ones(96,256,2).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
